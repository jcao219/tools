Command
=======

Commands available to the `cs3110` executable.
Each has some documentation inside the `.ml` file, and the command-line interface has summaries and readmes.

All the interfaces are as sparse as possible.

Clean
-----
Removes files generated by other commands.
Most output is stored under the folder named `_cs3110`, but compiler output is in the `_build` directory and custom output could be anywhere.

CMS
---
Convenience script for converting a harness-generated grades table into a CMS-ready one.

The "official" CMS format is very simple.
It expects a "NetID" column, an optional "Totals" column, an optional "Add Comments" column.
Any other columns included in the spreadsheet must match a the name of a problem on the CMS assignment.

The goal of `cs3110 cms` is to pull subtotals from a larger grades spreadsheet and add harness-generated comments.
Expected workflow is:
- Run `cs3110 harness` to generate a `grades_table.csv` with filled-in columns for each unit test and blank columns for each test file.
- Edit `grades_table.csv`, filling the blank columns with totals
- Run `cs3110 cms grades_table2.csv -i comments/`, where `grades_table2.csv` is the spreadsheet with totals computed and `comments/` is the harness-generated directory of grading comments organized by net id.

_Important Note_: the CMS command follows a 3-step fallback plan for choosing columns to save:
1. Taking the strings passed in with the `-c` option. For example, `cs3110 cms -c COL1 -c COL2 spreadsheet.csv`.
2. Searching the config file `.cs3110` for any entry `cms.column_names = COL1, COL2`.
3. Parsing capitalized column names from the input spreadsheet.

Because 3 is the last-resort / default behavior, it is good practice to begin unit test names with a lowercase character.
The harness will automatically capitalize the blank totals columns (think, OCaml modules vs. OCaml variable names).

Compile
-------
Simple wrapper for `ocamlbuild`.
Searches for a modules dependencies and compiles a bytecode executable.

Additional compiler options can be set using the config file `./.cs3110`.

Diff
----
Tool for comparing students' current and past submissions.
Given a list of current submissions, searches a directory of old submissions for any matches and if so outputs a diff.
Diffs are not generated if the old fle is empty (did not originally submit) or the new and old files match.

The original use-case is to implement no-compile grace period.
If the assignment deadline was Thursday, we'd compile submissions using `cs3110 smoke` that night, and send emails soon afterward to students whose submissions did not compile.
Students could then resubmit by Sunday to avoid getting a zero on the assignment.

If the difference between new and old files was big, they'd lose a slip day.
If not, no penalty.
Hence the need for a tool to compare submissions on a large scale.

Doc
---
Simple wrapper for `ocamldoc`.
Given a list of `.ml` or `.mli` files, attempts to create their documentation using the compiler output in the `_build` directory.

Email
-----
Used to send lots and lots of emails.
With great power comes great responsibility.

Searches a directory for email message files that look like `<netid>.txt` and sends their contents to the address `<netid>@cornell.edu`.
You can optionally name admins (the professor, yourself) to be included as hidden recipients (bcc's) of the email messages.

Harness
-------
Tool for running the tests contained in one or more test files on a list of submission directories.
Output is saved in a grades table, in CMS-ready markdown and, optionally, postscript.
(The grades table is global, the markdown is per-student, the postscript is per test file per student.)

Note: a "test" or "test file" is an OCaml module containing some inline tests.
A "unit test" is one of those inline tests.

Test files are copied into students' directories, then compiled and run using `cs3110 compile` and `cs3110 test`, respectively.
Test output is saved into two intermediate files -- one containing unit test names and one containing failure messages.
We scrape these to build the final results for each student.

Run
---
Umm, `cs3110 run file args` is literally `./_build/file.d.byte args`.
I suppose this could change in the future, but for now the command is really simple.

Smoke
-----
Tool for checking that students' submissions compile.
Given a list of directories and the names of files to compile, tries to compile each file in each directory.

If a students files don't compile, we save an email message and a copy of the submission for that student.

Test
----
Use `cs3110 test file` to run the inline tests within a file.
This is essentially a wrapper for `./_build/file.d.byte inline-test-runner target`, but there are conveniences for making and saving output.

Implementation Details
======================
As of August 12, 2014, these are things conscientious hackers should be aware of.

Tests and print statements
--------------------------

When `Test.test` is run with the arg `?quiet`, all output (`stdout` and `stderr`) is redirected to `/dev/null`.
When the options `?quiet` and `?output` is given, `stdout` is redirected to `/dev/null`, to hide students' print statements, and `stderr` is saved to a file.

Otherwise, print statements should appear as they would at runtime.

Harness-Test Contracts
----------------------
The connection between `harness.ml` and `test.ml` is important.

First, any time `Test.test` is run (more specifically, any time the `pa_ounit` inline test runner is run with the `-log` option), a file is created containing all unit test names.
This file is called `inline_tests.log`, better known to the harness as `Cli_config.cPA_OUNIT_LOGFILE`.
We use this file in the harness to collect test names in the function `Harness.get_unittest_names` by doing the following for each test file:

1. Copying the test file into a directory that is known to compile. (It can be the release, it doesn't have to work, but it's very important it compiles.)
2. Running the unit test in the file and reading this logfile as a newline-separated list of strings.
3. Using the function `Harness.unittest_name_of_line` to extract the unittest name from a line of this logfile.

Second, any time `Test.test` is run with the arguments `?quiet` and `?output`, we redirect the error messages produced by the unit test runner to a file.
(Specifically, we save `stderr` and suppress `stdout`. Leaving off the `?quiet` argument saves both `stdout` and `stderr`.)
The harness gives these arguments when executing `Test.test` on students' tests, saving the output to the file `Cli_config.harness.temporary_failures_file`.
This file is parsed in `Harness.run_test` to get scores and the error messages we give to students.
This function again uses the helper `Harness.unittest_name_of_line` and additionally, for quickcheck tests, the helper `Harness.parse_qcheck_failures`.

Partial Credit for Quickcheck Tests
-----------------------------------

Problem: the harness needs to know how many quickcheck test cases failed for a unit test.

Solution: the wrapper `Assertions.assert_qcheck` throws an exception if any subcases fail.
This exception contains the number that failed and is printed by the inline test runner (by `Test.test`) to the file `Cli_config.harness.temporary_failures_file`.
This file is later read by the harness in `Harness.parse_harness_result` when trying to see if unit tests passed or failed, and the line of error is interpreted by `Harness.parse_qcheck_failures` as a QCheck result and parsed for an integer.

That's how we determine partial credit.
It is not pretty.
